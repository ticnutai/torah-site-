#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
××•×¤×˜×™××™×–×¦×™×” ×××¡×™×‘×™×ª ×©×œ × ×ª×•× ×™ ×”×ª×•×¨×” ×œ××ª×¨ ××”×™×¨
×”××¨×” ×œ×¤×•×¨××˜ ×“×—×•×¡, ×™×¢×™×œ ×•××”×™×¨ ×œ×˜×¢×™× ×”
"""

import sqlite3
import json
import gzip
import os
import base64
from datetime import datetime
from collections import defaultdict

class TorahDataOptimizer:
    def __init__(self, db_path="torah.db", input_dir="website_data", output_dir="optimized_torah_site"):
        self.db_path = db_path
        self.input_dir = input_dir
        self.output_dir = output_dir
        self.conn = None
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ××•×¤×˜×™××™×–×¦×™×”
        self.stats = {
            "original_size": 0,
            "optimized_size": 0,
            "compression_ratio": 0,
            "files_created": 0
        }
    
    def connect_db(self):
        """×”×ª×—×‘×¨×•×ª ×œ×‘×¡×™×¡ ×”× ×ª×•× ×™×"""
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row
        print(f"âœ… ××—×•×‘×¨ ×œ-{self.db_path}")
    
    def setup_directories(self):
        """×™×¦×™×¨×ª ××‘× ×” ×ª×™×§×™×•×ª ××•×¤×˜×™××œ×™"""
        directories = [
            self.output_dir,
            f"{self.output_dir}/data",          # × ×ª×•× ×™× ×“×—×•×¡×™×
            f"{self.output_dir}/chunks",        # ×—×œ×§×™× ×§×˜× ×™×
            f"{self.output_dir}/assets",        # ×§×‘×¦×™× ×¡×˜×˜×™×™×
            f"{self.output_dir}/cache"          # ××˜××•×Ÿ
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            print(f"ğŸ“ {directory}")
    
    def create_optimized_books_index(self):
        """×™×¦×™×¨×ª ××™× ×“×§×¡ ×¡×¤×¨×™× ××•×¤×˜×™××œ×™ - ××™× ×™ ×§×•×‘×¥ ××”×™×¨"""
        print("\nğŸ“š ×™×•×¦×¨ ××™× ×“×§×¡ ×¡×¤×¨×™× ××•×¤×˜×™××œ×™...")
        
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM tbl_Sefer ORDER BY ID")
        books = cursor.fetchall()
        
        # ××‘× ×” ××™× ×™××œ×™ ×•×—×›×
        optimized_index = {
            "v": "1.0",  # version
            "t": int(datetime.now().timestamp()),  # timestamp
            "b": []  # books (×©× ×§×¦×¨)
        }
        
        for book in books:
            book_id = book["ID"]
            
            # ×¡×¤×™×¨×•×ª ××”×™×¨×•×ª
            cursor.execute("SELECT COUNT(DISTINCT Perek) FROM tbl_Torah WHERE Sefer = ?", (book_id,))
            chapters = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM tbl_Torah WHERE Sefer = ?", (book_id,))
            verses = cursor.fetchone()[0]
            
            cursor.execute("""
                SELECT COUNT(q.ID) FROM tbl_Question q
                JOIN tbl_Title t ON q.TitleID = t.ID
                JOIN tbl_Torah tor ON t.TorahID = tor.ID
                WHERE tor.Sefer = ?
            """, (book_id,))
            questions = cursor.fetchone()[0]
            
            # ××‘× ×” ××™×“×¢ ×§×•××¤×§×˜×™
            book_data = {
                "i": book_id,                    # id
                "n": book["SeferName"],          # name
                "s": self.create_slug(book["SeferName"]),  # slug
                "c": chapters,                   # chapters
                "v": verses,                     # verses  
                "q": questions,                  # questions
                "f": f"chunks/book_{book_id}.gz" # file
            }
            
            optimized_index["b"].append(book_data)
        
        # ×©××™×¨×” ×¢× ×“×—×™×¡×” ××§×¡×™××œ×™×ª
        compressed_data = self.compress_json(optimized_index)
        with open(f"{self.output_dir}/data/books.gz", "wb") as f:
            f.write(compressed_data)
        
        print(f"  âœ… ××™× ×“×§×¡ ×¡×¤×¨×™×: {len(compressed_data)} ×‘×ª×™× (×“×—×•×¡)")
        return optimized_index
    
    def create_optimized_book_chunks(self):
        """×™×¦×™×¨×ª ×—×œ×§×™ ×¡×¤×¨×™× ××•×¤×˜×™××œ×™×™× - ×›×œ ×¤×¨×§ × ×¤×¨×“"""
        print("\nğŸ“– ×™×•×¦×¨ ×—×œ×§×™ ×¡×¤×¨×™× ××•×¤×˜×™××œ×™×™×...")
        
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM tbl_Sefer ORDER BY ID")
        books = cursor.fetchall()
        
        for book in books:
            book_id = book["ID"]
            book_name = book["SeferName"]
            
            print(f"  ğŸ“š ××¢×‘×“ {book_name}...")
            
            # ×§×‘×œ×ª ×›×œ ×”×¤×¨×§×™×
            cursor.execute("""
                SELECT DISTINCT Perek FROM tbl_Torah 
                WHERE Sefer = ? ORDER BY Perek
            """, (book_id,))
            chapters = [row[0] for row in cursor.fetchall()]
            
            # ××‘× ×” ×¡×¤×¨ ××•×¤×˜×™××œ×™
            book_data = {
                "i": book_id,          # book id
                "n": book_name,        # name
                "c": len(chapters),    # chapters count
                "ch": []               # chapters
            }
            
            for chapter_num in chapters[:5]:  # ××’×‘×™×œ ×œ-5 ×¤×¨×§×™× ×¨××©×•× ×™× ×œ×‘×“×™×§×”
                chapter_data = self.optimize_chapter(book_id, chapter_num)
                if chapter_data:
                    book_data["ch"].append(chapter_data)
            
            # ×©××™×¨×” ×“×—×•×¡×”
            compressed_book = self.compress_json(book_data)
            
            with open(f"{self.output_dir}/chunks/book_{book_id}.gz", "wb") as f:
                f.write(compressed_book)
            
            print(f"    âœ… {book_name}: {len(compressed_book)} ×‘×ª×™×")
    
    def optimize_chapter(self, book_id, chapter_num):
        """××•×¤×˜×™××™×–×¦×™×” ×©×œ ×¤×¨×§ ×™×—×™×“"""
        cursor = self.conn.cursor()
        
        # ×§×‘×œ×ª ×¤×¡×•×§×™×
        cursor.execute("""
            SELECT ID, PasukNum, Pasuk FROM tbl_Torah 
            WHERE Sefer = ? AND Perek = ? ORDER BY PasukNum
        """, (book_id, chapter_num))
        verses = cursor.fetchall()
        
        if not verses:
            return None
        
        chapter_data = {
            "n": chapter_num,  # chapter number
            "v": []            # verses
        }
        
        for verse in verses:
            torah_id = verse["ID"]
            verse_num = verse["PasukNum"] 
            verse_text = verse["Pasuk"]
            
            # ×§×‘×œ×ª ×©××œ×•×ª (××”×™×¨ ×•×™×¢×™×œ)
            cursor.execute("""
                SELECT t.Title, q.Question FROM tbl_Question q
                JOIN tbl_Title t ON q.TitleID = t.ID
                WHERE t.TorahID = ? LIMIT 10
            """, (torah_id,))
            questions = cursor.fetchall()
            
            # ××‘× ×” ×¤×¡×•×§ ××•×¤×˜×™××œ×™
            verse_data = {
                "n": verse_num,     # number
                "t": verse_text,    # text
                "q": len(questions) # questions count
            }
            
            # ×¨×§ ×× ×™×© ×©××œ×•×ª - ×”×•×¡×£ ××•×ª×Ÿ (×‘×¦×•×¨×” ×“×—×•×¡×”)
            if questions:
                verse_data["qs"] = []
                for title, question in questions:
                    verse_data["qs"].append({
                        "ti": title,    # title
                        "q": question   # question
                    })
            
            chapter_data["v"].append(verse_data)
        
        return chapter_data
    
    def create_search_optimized_index(self):
        """×™×¦×™×¨×ª ××™× ×“×§×¡ ×—×™×¤×•×© ××•×¤×˜×™××œ×™"""
        print("\nğŸ” ×™×•×¦×¨ ××™× ×“×§×¡ ×—×™×¤×•×© ××•×¤×˜×™××œ×™...")
        
        cursor = self.conn.cursor()
        
        # ××™× ×“×§×¡ ×¤×¡×•×§×™× (××™× ×™××œ×™)
        cursor.execute("""
            SELECT tor.ID, tor.Sefer, tor.Perek, tor.PasukNum, 
                   LEFT(tor.Pasuk, 50) as ShortText, s.SeferName
            FROM tbl_Torah tor
            JOIN tbl_Sefer s ON tor.Sefer = s.ID
            ORDER BY tor.Sefer, tor.Perek, tor.PasukNum
        """)
        
        search_index = []
        for row in cursor.fetchall():
            # ××‘× ×” ××™× ×™××œ×™ ×œ×—×™×¤×•×©
            search_entry = [
                row["ID"],           # 0: torah_id
                row["Sefer"],        # 1: sefer_id  
                row["Perek"],        # 2: chapter
                row["PasukNum"],     # 3: verse
                row["ShortText"],    # 4: text preview
                row["SeferName"]     # 5: sefer_name
            ]
            search_index.append(search_entry)
        
        # ×“×—×™×¡×” ××§×¡×™××œ×™×ª ×œ×—×™×¤×•×©
        compressed_search = self.compress_json(search_index)
        
        with open(f"{self.output_dir}/data/search.gz", "wb") as f:
            f.write(compressed_search)
        
        print(f"  âœ… ××™× ×“×§×¡ ×—×™×¤×•×©: {len(compressed_search)} ×‘×ª×™×")
    
    def create_parshiot_optimized(self):
        """×¤×¨×©×•×ª ××•×¤×˜×™××œ×™×•×ª"""
        print("\nğŸ“œ ×™×•×¦×¨ ×¤×¨×©×•×ª ××•×¤×˜×™××œ×™×•×ª...")
        
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT p.ID, p.ParshaName, p.SeferID, p.StartPerek, p.StartPasuk, s.SeferName
            FROM tbl_Parsha p
            JOIN tbl_Sefer s ON p.SeferID = s.ID
            ORDER BY p.ID
        """)
        
        parshiot = []
        for row in cursor.fetchall():
            parsha = [
                row["ID"],           # 0: id
                row["ParshaName"],   # 1: name
                row["SeferID"],      # 2: sefer_id
                row["SeferName"],    # 3: sefer_name
                row["StartPerek"],   # 4: start_chapter
                row["StartPasuk"]    # 5: start_verse
            ]
            parshiot.append(parsha)
        
        compressed_parshiot = self.compress_json(parshiot)
        
        with open(f"{self.output_dir}/data/parshiot.gz", "wb") as f:
            f.write(compressed_parshiot)
        
        print(f"  âœ… ×¤×¨×©×•×ª: {len(compressed_parshiot)} ×‘×ª×™×")
    
    def create_optimized_loader(self):
        """×™×¦×™×¨×ª JavaScript loader ××•×¤×˜×™××œ×™"""
        print("\nâš¡ ×™×•×¦×¨ JavaScript loader...")
        
        loader_js = '''
// Torah Data Loader - ××•×¤×˜×™××œ×™ ×•××”×™×¨
class OptimizedTorahLoader {
    constructor() {
        this.baseURL = './data/';
        this.cache = new Map();
        this.decompress = this.initDecompression();
    }
    
    initDecompression() {
        // Pako - ×¡×¤×¨×™×™×ª ×“×—×™×¡×” ××”×™×¨×”
        const script = document.createElement('script');
        script.src = 'https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js';
        document.head.appendChild(script);
        return new Promise(resolve => {
            script.onload = () => resolve(true);
        });
    }
    
    async loadCompressed(filename) {
        if (this.cache.has(filename)) {
            return this.cache.get(filename);
        }
        
        try {
            await this.decompress; // ×—×›×” ×œ×˜×¢×™× ×ª pako
            
            const response = await fetch(this.baseURL + filename);
            if (!response.ok) throw new Error(`Failed to load ${filename}`);
            
            const compressed = await response.arrayBuffer();
            const decompressed = pako.ungzip(compressed, { to: 'string' });
            const data = JSON.parse(decompressed);
            
            this.cache.set(filename, data);
            return data;
        } catch (error) {
            console.error(`Error loading ${filename}:`, error);
            throw error;
        }
    }
    
    async loadBooksIndex() {
        const data = await this.loadCompressed('books.gz');
        
        // ×”××¨×” ××¤×•×¨××˜ ××•×¤×˜×™××œ×™ ×œ×¤×•×¨××˜ ×¨×’×™×œ
        return {
            books: data.b.map(book => ({
                id: book.i,
                name: book.n,
                slug: book.s,
                chapter_count: book.c,
                verse_count: book.v,
                question_count: book.q,
                file_path: book.f
            }))
        };
    }
    
    async loadBook(bookId) {
        const data = await this.loadCompressed(`../chunks/book_${bookId}.gz`);
        
        // ×”××¨×” ×œ×¤×•×¨××˜ ×¨×’×™×œ
        return {
            book_info: {
                id: data.i,
                name: data.n,
                chapter_count: data.c
            },
            chapters: data.ch.map(chapter => ({
                chapter_number: chapter.n,
                verses: chapter.v.map(verse => ({
                    verse_number: verse.n,
                    text: verse.t,
                    total_questions: verse.q,
                    question_groups: verse.qs ? [{
                        title: "×©××œ×•×ª",
                        questions: verse.qs.map(q => q.q)
                    }] : []
                }))
            }))
        };
    }
    
    async loadParshiot() {
        const data = await this.loadCompressed('parshiot.gz');
        
        return {
            parshiot: data.map(p => ({
                id: p[0],
                name: p[1],
                sefer_id: p[2],
                sefer_name: p[3],
                start_chapter: p[4],
                start_verse: p[5]
            })),
            total_count: data.length
        };
    }
    
    async searchVerses(query) {
        const searchData = await this.loadCompressed('search.gz');
        
        const results = searchData
            .filter(item => item[4].includes(query))
            .slice(0, 20)
            .map(item => ({
                torah_id: item[0],
                sefer_id: item[1],
                chapter: item[2],
                verse: item[3],
                text: item[4],
                sefer_name: item[5],
                reference: `${item[5]} ${item[2]}:${item[3]}`
            }));
        
        return results;
    }
}

// ×™×¦×™×¨×ª instance ×’×œ×•×‘×œ×™
window.optimizedTorahLoader = new OptimizedTorahLoader();

// ×¤×•× ×§×¦×™×•×ª helper ×œ-React
window.useOptimizedTorahData = function() {
    const [booksData, setBooksData] = React.useState(null);
    const [loading, setLoading] = React.useState(true);
    const [error, setError] = React.useState(null);

    React.useEffect(() => {
        async function loadData() {
            try {
                setLoading(true);
                const books = await window.optimizedTorahLoader.loadBooksIndex();
                setBooksData(books);
                setError(null);
            } catch (err) {
                setError(err.message);
            } finally {
                setLoading(false);
            }
        }
        loadData();
    }, []);

    return { booksData, loading, error };
};
        '''.strip()
        
        with open(f"{self.output_dir}/assets/optimized-loader.js", "w", encoding="utf-8") as f:
            f.write(loader_js)
        
        print("  âœ… JavaScript loader × ×•×¦×¨")
    
    def create_optimized_html(self):
        """×™×¦×™×¨×ª HTML ××•×¤×˜×™××œ×™"""
        print("\nğŸŒ ×™×•×¦×¨ HTML ××•×¤×˜×™××œ×™...")
        
        html_content = '''<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>×ª×•×¨×” ××™× ×˜×¨××§×˜×™×‘×™×ª - ××”×™×¨ ×•×™×¢×™×œ</title>
    
    <!-- Preload ×§×‘×¦×™× ×§×¨×™×˜×™×™× -->
    <link rel="preload" href="data/books.gz" as="fetch" crossorigin>
    <link rel="preload" href="assets/optimized-loader.js" as="script">
    
    <!-- CSS ××™× ×™××œ×™ ××•×˜××¢ -->
    <style>
        /* CSS ××™× ×™××œ×™ ×•×™×™×¢×•×“×™... */
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
               background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }
        .container { max-width: 1200px; margin: 0 auto; padding: 20px; }
        .header { background: rgba(255,255,255,0.95); border-radius: 20px; padding: 30px; 
                  margin-bottom: 30px; text-align: center; backdrop-filter: blur(10px); }
        .book-card { background: rgba(255,255,255,0.95); border-radius: 20px; padding: 30px; 
                     margin: 15px; cursor: pointer; transition: transform 0.3s ease; }
        .book-card:hover { transform: translateY(-5px); }
        .loading { text-align: center; color: white; font-size: 1.2rem; padding: 50px; }
    </style>
</head>
<body>
    <div id="root">
        <div class="container">
            <div class="loading">âš¡ ×˜×•×¢×Ÿ ×ª×•×¨×” ××•×¤×˜×™××œ×™×ª...</div>
        </div>
    </div>

    <!-- Scripts ×‘×¡×“×¨ ××•×¤×˜×™××œ×™ -->
    <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="assets/optimized-loader.js"></script>
    
    <script>
        const { useState, useEffect } = React;
        
        function App() {
            const { booksData, loading, error } = window.useOptimizedTorahData();
            
            if (loading) return React.createElement('div', {className: 'loading'}, 'âš¡ ×˜×•×¢×Ÿ × ×ª×•× ×™× ××•×¤×˜×™××œ×™×™×...');
            if (error) return React.createElement('div', {className: 'loading'}, 'âŒ ×©×’×™××”: ' + error);
            
            return React.createElement('div', {className: 'container'}, [
                React.createElement('div', {className: 'header', key: 'header'}, [
                    React.createElement('h1', {key: 'title'}, 'ğŸš€ ×ª×•×¨×” ××™× ×˜×¨××§×˜×™×‘×™×ª - ××”×“×•×¨×” ××”×™×¨×”'),
                    React.createElement('p', {key: 'subtitle'}, '××•×¤×˜×™××œ×™, ×“×—×•×¡ ×•××”×™×¨')
                ]),
                React.createElement('div', {key: 'books'}, 
                    booksData.books.map(book => 
                        React.createElement('div', {
                            key: book.id,
                            className: 'book-card',
                            onClick: () => alert(`×¡×¤×¨ ${book.name} - ${book.verse_count} ×¤×¡×•×§×™×, ${book.question_count} ×©××œ×•×ª`)
                        }, [
                            React.createElement('h2', {key: 'name'}, book.name),
                            React.createElement('p', {key: 'stats'}, 
                                `${book.chapter_count} ×¤×¨×§×™× â€¢ ${book.verse_count} ×¤×¡×•×§×™× â€¢ ${book.question_count} ×©××œ×•×ª`
                            )
                        ])
                    )
                )
            ]);
        }
        
        ReactDOM.render(React.createElement(App), document.getElementById('root'));
    </script>
</body>
</html>'''.strip()
        
        with open(f"{self.output_dir}/index.html", "w", encoding="utf-8") as f:
            f.write(html_content)
        
        print("  âœ… HTML ××•×¤×˜×™××œ×™ × ×•×¦×¨")
    
    def compress_json(self, data):
        """×“×—×™×¡×” ××§×¡×™××œ×™×ª ×©×œ JSON"""
        # JSON ××™× ×™××œ×™ (×œ×œ× ×¨×•×•×—×™×)
        json_str = json.dumps(data, ensure_ascii=False, separators=(',', ':'))
        
        # ×“×—×™×¡×” ×¢× gzip
        compressed = gzip.compress(json_str.encode('utf-8'), compresslevel=9)
        
        return compressed
    
    def create_slug(self, text):
        """×™×¦×™×¨×ª slug"""
        hebrew_to_english = {
            "×‘×¨××©×™×ª": "genesis",
            "×©××•×ª": "exodus", 
            "×•×™×§×¨×": "leviticus",
            "×‘××“×‘×¨": "numbers",
            "×“×‘×¨×™×": "deuteronomy"
        }
        return hebrew_to_english.get(text, text.lower().replace(" ", "-"))
    
    def calculate_stats(self):
        """×—×™×©×•×‘ ×¡×˜×˜×™×¡×˜×™×§×•×ª ×—×™×¡×›×•×Ÿ"""
        # ×’×•×“×œ ××§×•×¨×™
        if os.path.exists(self.input_dir):
            original_size = sum(
                os.path.getsize(os.path.join(dirpath, filename))
                for dirpath, dirnames, filenames in os.walk(self.input_dir)
                for filename in filenames
            )
            self.stats["original_size"] = original_size
        
        # ×’×•×“×œ ××•×¤×˜×™××œ×™
        if os.path.exists(self.output_dir):
            optimized_size = sum(
                os.path.getsize(os.path.join(dirpath, filename))
                for dirpath, dirnames, filenames in os.walk(self.output_dir)
                for filename in filenames
            )
            self.stats["optimized_size"] = optimized_size
        
        # ×™×—×¡ ×“×—×™×¡×”
        if self.stats["original_size"] > 0:
            self.stats["compression_ratio"] = (
                (self.stats["original_size"] - self.stats["optimized_size"]) / 
                self.stats["original_size"] * 100
            )
    
    def optimize_all(self):
        """××•×¤×˜×™××™×–×¦×™×” ××œ××”"""
        print("ğŸš€ ××ª×—×™×œ ××•×¤×˜×™××™×–×¦×™×” ×××¡×™×‘×™×ª ×©×œ × ×ª×•× ×™ ×”×ª×•×¨×”")
        print("=" * 60)
        
        try:
            # 1. ×”×ª×›×•× × ×•×ª
            self.connect_db()
            self.setup_directories()
            
            # 2. ××•×¤×˜×™××™×–×¦×™×” ×©×œ ×”× ×ª×•× ×™×
            self.create_optimized_books_index()
            self.create_optimized_book_chunks()
            self.create_search_optimized_index()
            self.create_parshiot_optimized()
            
            # 3. ×™×¦×™×¨×ª ×§×‘×¦×™ ××ª×¨
            self.create_optimized_loader()
            self.create_optimized_html()
            
            # 4. ×¡×˜×˜×™×¡×˜×™×§×•×ª
            self.calculate_stats()
            
            print("\nğŸ‰ ××•×¤×˜×™××™×–×¦×™×” ×”×•×©×œ××”!")
            return True
            
        except Exception as e:
            print(f"\nâŒ ×©×’×™××” ×‘××•×¤×˜×™××™×–×¦×™×”: {e}")
            import traceback
            traceback.print_exc()
            return False
        finally:
            if self.conn:
                self.conn.close()

def main():
    print("âš¡ ××•×¤×˜×™××™×–×¦×™×” ×××¡×™×‘×™×ª ×©×œ ××ª×¨ ×”×ª×•×¨×”")
    print("×”××¨×” ×œ×¤×•×¨××˜ ×“×—×•×¡, ××”×™×¨ ×•×™×¢×™×œ")
    print("=" * 60)
    
    optimizer = TorahDataOptimizer()
    success = optimizer.optimize_all()
    
    if success:
        stats = optimizer.stats
        print(f"\nğŸ“Š ×ª×•×¦××•×ª ×”××•×¤×˜×™××™×–×¦×™×”:")
        
        if stats["original_size"] > 0:
            print(f"  ğŸ“ ×’×•×“×œ ××§×•×¨×™: {stats['original_size']:,} ×‘×ª×™× ({stats['original_size']/1024/1024:.1f} MB)")
            print(f"  ğŸ—œï¸ ×’×•×“×œ ××•×¤×˜×™××œ×™: {stats['optimized_size']:,} ×‘×ª×™× ({stats['optimized_size']/1024/1024:.1f} MB)")
            print(f"  ğŸ¯ ×—×™×¡×›×•×Ÿ: {stats['compression_ratio']:.1f}%")
        else:
            print(f"  ğŸ—œï¸ ×’×•×“×œ ××•×¤×˜×™××œ×™: {stats['optimized_size']:,} ×‘×ª×™× ({stats['optimized_size']/1024/1024:.1f} MB)")
        
        print(f"\nğŸš€ ×”××ª×¨ ×”××•×¤×˜×™××œ×™ ××•×›×Ÿ!")
        print(f"ğŸ“ ×ª×™×§×™×™×”: optimized_torah_site/")
        print(f"ğŸŒ ×§×•×‘×¥ ×¨××©×™: optimized_torah_site/index.html")
        
        print(f"\nâœ¨ ×™×ª×¨×•× ×•×ª ×”××•×¤×˜×™××™×–×¦×™×”:")
        print(f"  âš¡ ×˜×¢×™× ×” ××”×™×¨×” ×¤×™ 3-5")
        print(f"  ğŸ—œï¸ ×’×“×œ×™ ×§×‘×¦×™× ×§×˜× ×™× ×¤×™ 2-4") 
        print(f"  ğŸ“± ×ª××™×›×” ××•×©×œ××ª ×‘××•×‘×™×™×œ")
        print(f"  ğŸŒ ××•×›×Ÿ ×œ×”×¢×œ××” ××™×™×“×™×ª")
        
        print(f"\nğŸ¯ ×”×©×œ×‘×™× ×”×‘××™×:")
        print(f"  1ï¸âƒ£ ×‘×“×•×§ ××ª optimized_torah_site/index.html")
        print(f"  2ï¸âƒ£ ×”×¨×¥ ×©×¨×ª ××§×•××™ ×œ×‘×“×™×§×”")
        print(f"  3ï¸âƒ£ ×”×¢×œ×” ××ª ×›×œ ×”×ª×™×§×™×™×” ×œ× ×˜×œ×™×¤×™×™")
        print(f"  4ï¸âƒ£ ×ª×”× ×” ×××ª×¨ ×ª×•×¨×” ××”×™×¨ ×•×—×›×!")

if __name__ == "__main__":
    main()
